server:
  port: 8001

spring:
  kafka:
    #Kafka cluster, mutilper with ','
    bootstrap-servers: 127.0.0.1:9092
    producer:
      retries: 0
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # acks=0 ： 生产者在成功写入消息之前不会等待任何来自服务器的响应。
      # acks=1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
      # acks=all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
      acks: 1
    consumer:
      auto-commit-interval: 1S
      # latest（默认值）在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）
      # earliest ：在偏移量无效的情况下，消费者将从起始位置读取分区的记录
      auto-offset-reset: earliest
      # 是否自动提交偏移量，默认值是true,为了避免出现重复数据和数据丢失，可以把它设置为false,然后手动提交偏移量
      enable-auto-commit: true
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      # 在侦听器容器中运行的线程数。
      concurrency: 5

#https://blog.csdn.net/u011798348/article/details/147637085
  #三者的关系
  #Topic 与 Partition：
  #Topic 是逻辑概念，Partition 是物理实现。
  #生产者向 Topic 发送消息，消息被分发到不同的 Partition。
  #Partition 数量决定 Topic 的并行处理能力。
  #Partition 与 Consumer Group：
  #同一 Consumer Group 中的消费者按 Partition 分配消费任务。
  #消费者数量 ≤ Partition 数量（多余的消费者会闲置）。
  #Consumer Group 与 Topic：
  #不同 Consumer Group 可独立消费同一 Topic（消息被多次消费，实现“发布-订阅”模式）。
  #同一 Consumer Group 内的消费者协作消费（实现“队列”模式）。

  #清理日志文件
  #如果Kafka日志文件损坏或无法访问，可以尝试手动删除E:\kafka_now\kafka_log目录中的内容。
  #注意：删除日志文件将导致Kafka无法恢复之前的状态，因此请确保在删除之前备份重要数据。